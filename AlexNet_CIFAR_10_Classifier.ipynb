{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4j5wa7AsROOS"
      },
      "source": [
        "## 1. Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1P6n6CkBRBur"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import Subset\n",
        "\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlBRyLdjRxpa"
      },
      "outputs": [],
      "source": [
        "\"\"\"In order force cuDNN to onyl use deterministic\n",
        "algorithms which might be useful to produce\n",
        "reproducible results we need following code\"\"\"\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLk-CDATSipS"
      },
      "source": [
        "## 2. Model settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNe2ISQuSciF"
      },
      "outputs": [],
      "source": [
        "# Setting a random seed\n",
        "def set_all_seeds(seed):\n",
        "  os.environ[\"PL_GLOBAL_SEED\"] = str(seed)\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUyWFb43TL8h"
      },
      "outputs": [],
      "source": [
        "# Setting cuDNN and PyTorch algorithmic behavior to deterministic\n",
        "def set_deterministic():\n",
        "  if torch.cuda_is_available():\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "  torch.set_deterministic(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Se7TTBrUx8Y"
      },
      "outputs": [],
      "source": [
        "#### SETTINGS ####\n",
        "\n",
        "# Hyperparameters\n",
        "RANDOM_SEED = 1\n",
        "LEARNING_RATE = 0.0001\n",
        "BATCH_SIZE = 16\n",
        "NUM_EPOCHS = 40\n",
        "\n",
        "# Architecture\n",
        "NUM_CLASSES=10\n",
        "\n",
        "#Other\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available else \"cpu\"\n",
        "\n",
        "set_all_seeds(RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2s1OeBBV6SR"
      },
      "outputs": [],
      "source": [
        "# Deterministic behavior not yet supported by AdaptiveAvgPool2d\n",
        "#set_deterministic()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_XssaqPV8wk"
      },
      "source": [
        "## 3. Import utility functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGLJlElkV7n1"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "# In order to import modules from a directory one level up.\n",
        "\n",
        "sys.path.append('/content/helper_functions/helper_data.py')\n",
        "sys.path.insert(0, \"..\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "BaYA9Jruhf5I",
        "outputId": "87215f12-f39a-4656-c684-1051d143c10c"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'helper_functions.helper_evaluate'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-2b8db2b0badb>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhelper_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhelper_evaluate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompute_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_epoch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhelper_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhelper_data\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhelper_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhelper_train\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'helper_functions.helper_evaluate'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from helper_functions.helper_evaluate import compute_accuracy, compute_epoch_loss\n",
        "\n",
        "from helper_functions.helper_data import *\n",
        "\n",
        "from helper_functions.helper_train import *\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xO1prwxOCId6"
      },
      "source": [
        "## 4. Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRBQ5-WiEVTU"
      },
      "outputs": [],
      "source": [
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slQrBxYICQHl"
      },
      "outputs": [],
      "source": [
        "## Set random seed##\n",
        "set_all_seeds(RANDOM_SEED)\n",
        "\n",
        "### Dataset ###\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize(70),\n",
        "    transforms.RandomCrop(64, 64),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize(size=(70,70)),\n",
        "    transforms.CenterCrop((64, 64)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_loader, valid_loader, test_loader = get_dataloaders_cifar10(\n",
        "    batch_size=BATCH_SIZE,\n",
        "    num_workers=2,\n",
        "    train_transforms=train_transforms,\n",
        "    test_transforms=test_transforms,\n",
        "    validation_fraction=0.1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7pSDwZDkDKEH"
      },
      "outputs": [],
      "source": [
        "# Checking the dataset\n",
        "print(f\"Training set:\\n\")\n",
        "for images, labels in train_loader:\n",
        "  print(f\"Image batch demensions: {images.size()}\")\n",
        "  print(f\"Image label dimensions: {labels.size()}\")\n",
        "  print(labels[:10])\n",
        "  break\n",
        "\n",
        "# Checking the validation set\n",
        "print(f\"\\nValidation set:\")\n",
        "for images, labels in valid_loader:\n",
        "  print(f\"Image batch demensions: {images.size()}\")\n",
        "  print(f\"Image label dimensions: {labels.size()}\")\n",
        "  print(labels[:10])\n",
        "  break\n",
        "\n",
        "# Checking the testing set\n",
        "print(f\"\\nTesting set:\")\n",
        "for images, labels in test_loader:\n",
        "  print(f\"Image batch demensions: {images.size()}\")\n",
        "  print(f\"Image label dimensions: {labels.size()}\")\n",
        "  print(labels[:10])\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdbDLKuUGjWU"
      },
      "source": [
        "## 5. Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgZ-tsHuJO9d"
      },
      "outputs": [],
      "source": [
        "### MODEL ###\n",
        "\n",
        "class AlexNet(nn.Module):\n",
        "  def __init__(self, num_classes):\n",
        "    super(AlexNet, self).__init__()\n",
        "    self.features = nn.Sequential(\n",
        "      nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "\n",
        "      nn.Conv2d(64, 192, kernel_size=5, padding=2, groups=2),\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "\n",
        "      nn.Conv2d(192, 384, kernel_size=3, padding=1, groups=2),\n",
        "      nn.ReLU(inplace=True),\n",
        "\n",
        "      nn.Conv2d(384, 256, kernel_size=3, padding=1, groups=2),\n",
        "      nn.ReLU(inplace=True),\n",
        "\n",
        "      nn.Conv2d(256, 256, kernel_size=3, padding=1, groups=2),\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "    )\n",
        "    self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(256*6*6, 4096),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(4096, 4096),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Linear(4096, num_classes),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.features(x)\n",
        "    x = self.avgpool(x)\n",
        "    x = x.view(x.size(0), 256*6*6)\n",
        "    logits = self.classifier(x)\n",
        "    probas = F.softmax(logits, dim=1)\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YstKF2dAMfae"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(RANDOM_SEED)\n",
        "model = AlexNet(NUM_CLASSES)\n",
        "model = model.to(DEVICE)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IChyTU2qM0Lh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
