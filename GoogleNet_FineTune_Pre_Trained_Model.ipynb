{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QnFLATpqvzGN"
   },
   "source": [
    "## FineTune pre-trained GoogleNet model on Intel Image Classification dataset :\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Q5D07vtwnle"
   },
   "source": [
    "### 0. Steps to download Kaggle datasets in Google Colab\n",
    "1.   Go to kaggle account *Profile>Settings>API* **Expire Token** and then **Create New Token** and it will download ***kaggle.json*** fie on your machine.\n",
    "2.   Go to your google colab project file and run folowing commands:\n",
    "  *   Install kaggle API client `!pip install -q kaggle`\n",
    "  *   Upload the kaggle.json file here\n",
    "  *   Kaggle API client expects the file to be in ~/.kaggle so move it there\n",
    "  *   `!mkdir -p ~/.kaggle`\n",
    "  *   `!mv kaggle.json ~/.kaggle`\n",
    "  *   `!chmod 600 ~/.kaggle/kaggle.json`\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8-lFII2yyIHI"
   },
   "source": [
    "### 1. Download NCT-CRC-HE-100K dataset from kaggle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the kaggle.json file here\n",
    "# Following command fill prompt you to upload the kaggle.json file\n",
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle API client expects the file to be in ~/.kaggle so move it there\n",
    "!mkdir -p ~/.kaggle\n",
    "!mv kaggle.json ~/.kaggle\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets download -d puneet6060/intel-image-classification -p /content --force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "with ZipFile(\"/content/intel-image-classification.zip\") as file:\n",
    "  file.extractall(\"/content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p /content/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv /content/seg_pred/seg_pred /content/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv /content/seg_train/seg_train /content/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv /content/seg_test/seg_test /content/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rmdir /content/seg_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rmdir /content/seg_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rmdir /content/seg_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /content/intel-image-classification.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"/content/data/seg_train\"\n",
    "test_dir = \"/content/data/seg_test\"\n",
    "pred_dir = \"/content/data/seg_pred\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HzRozlEk-YhG"
   },
   "source": [
    "### 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, models\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from typing import Tuple, Dict, List\n",
    "import pathlib\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SETTINGS ##\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Hyperparameter\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 10\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Architecture\n",
    "NUM_CLASSES = 6\n",
    "IN_CHANNELS = 3\n",
    "\n",
    "# Other\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0AAZyoXc92PD"
   },
   "source": [
    "### 2. Exploring dataset for all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def walkt_through_dir(dir_path):\n",
    "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
    "    print(dirpath)\n",
    "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walkt_through_dir(\"/content/data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iOdNnqsB_e4x"
   },
   "source": [
    "### 3. Create a Custom Dataset to replicate ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_classes(directory: str) -> Tuple[List[str], Dict[str, int]]:\n",
    "  \"\"\" Finds the class names in a target directory\n",
    "      by scanning through target directory\"\"\"\n",
    "\n",
    "  classes = sorted(entry.name for entry in os.scandir(directory) if entry.is_dir())\n",
    "  class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
    "  return classes, class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a custom dataset\n",
    "\n",
    "# 1. Subclass a torch.tuils.data.Dataset\n",
    "class ImageFolder(Dataset):\n",
    "\n",
    "  # 2. Initialize our custom dataset\n",
    "  def __init__(self,\n",
    "               targ_dir: str,\n",
    "               transform=None):\n",
    "    # 3. Create class attributes\n",
    "    # Get all of the image path\n",
    "\n",
    "    self.paths = list(pathlib.Path(targ_dir).glob(\"*/*.jpg\"))\n",
    "\n",
    "    # Setup transform\n",
    "    self.transform = transform\n",
    "\n",
    "    # Create classes and class_to_idx attributes\n",
    "    self.classes, self.class_to_idx = find_classes(targ_dir)\n",
    "\n",
    "  # 4. Create a function to load images\n",
    "  def load_image(self, index: int) -> Image.Image:\n",
    "    \"Opens and transforms an image into a PyTorch image\"\n",
    "    image_path = self.paths[index]\n",
    "    return Image.open(image_path)\n",
    "\n",
    "  # 5. Overwrite __len__()\n",
    "  def __len__(self) -> int:\n",
    "    return len(self.paths)\n",
    "\n",
    "  # 6. Overwrite __get_item() method to return a particular sample\n",
    "  def __getitem__(self, index: int) -> Tuple[torch.Tensor, int]:\n",
    "    img = self.load_image(index)\n",
    "    class_name = self.paths[index].parent.name\n",
    "    class_idx = self.class_to_idx[class_name]\n",
    "\n",
    "    # Transform if necessary\n",
    "    if self.transform:\n",
    "      return self.transform(img), class_idx\n",
    "    else:\n",
    "      return img, class_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_classes(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a transform\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                      std=[0.229, 0.224, 0.225])\n",
    "\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test out ImageFolder\n",
    "\n",
    "train_data = ImageFolder(\n",
    "    train_dir,\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "test_data = ImageFolder(\n",
    "    test_dir,\n",
    "    transform=test_transform\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, (img, label) in enumerate(train_loader):\n",
    "  print(f\"Image shape: {img.shape}\")\n",
    "  print(f\"Label shape: {label.shape}\")\n",
    "  break\n",
    "\n",
    "for batch_idx, (img, label) in enumerate(test_loader):\n",
    "  print(f\"Image shape: {img.shape}\")\n",
    "  print(f\"Label shape: {label.shape}\")\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3h5t0TWAfLrR"
   },
   "source": [
    "#### 3.1 Show sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "images_10 = images[:10]\n",
    "labels_10 = labels[:10]\n",
    "\n",
    "class_names = train_data.classes\n",
    "\n",
    "# Plot 10 images\n",
    "plt.figure(figsize=(15, 6))\n",
    "for i in range(10):\n",
    "  img = images_10[i].permute(1, 2, 0).numpy()\n",
    "  plt.subplot(2, 5, i+1)\n",
    "  plt.imshow(img)\n",
    "  plt.title(class_names[labels_10[i]])\n",
    "  plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QX45l1QNhqM-"
   },
   "source": [
    "### 4. Transfer learning from pre trained GoogleNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.googlenet(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze eearly layers\n",
    "\n",
    "for layer in model.modules():\n",
    "  if not isinstance(layer, nn.Linear):\n",
    "    layer.requires_grad_(False)\n",
    "  else:\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup loss function and optimizer\n",
    "model.to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Set random seeds\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HP9gNcBikR3K"
   },
   "source": [
    "#### 4.1 Create train and test loop functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module,\n",
    "               dataloader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer):\n",
    "  # Put model in train mode\n",
    "  model.train()\n",
    "  model = model.to(device)\n",
    "\n",
    "  # Setup train loss and train accuracy values\n",
    "  train_loss, train_acc = 0, 0\n",
    "\n",
    "  # Loop through data loader data batches\n",
    "  for batch, (X, y) in enumerate(dataloader):\n",
    "    # Send data to target device\n",
    "    X, y = X.to(device), y.to(device)\n",
    "\n",
    "    # 1. Forward pass\n",
    "    y_pred = model(X)\n",
    "\n",
    "    # 2.Calculate the loss\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    train_loss += loss.item()\n",
    "\n",
    "    # 3. Optimizer zero_grad()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 4. Loss backward\n",
    "    loss.backward()\n",
    "\n",
    "    # 5. Optimizer step\n",
    "    optimizer.step()\n",
    "\n",
    "    # Calculate and accumulate accuracy metrics accross all batches\n",
    "    y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "    train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
    "\n",
    "  # Adjust metrics to get avarage loss and accuracy per batch\n",
    "  train_loss = train_loss / len(dataloader)\n",
    "  train_acc = train_acc / len(dataloader)\n",
    "  return train_loss, train_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(\n",
    "    model: torch.nn.Module,\n",
    "    dataloader: torch.utils.data.DataLoader,\n",
    "    loss_fn: torch.nn.Module):\n",
    "  # Put model in eval mode\n",
    "  model.eval()\n",
    "  model.to(device)\n",
    "\n",
    "  # Set up test loss an test accuracy values\n",
    "  test_loss, test_acc = 0, 0\n",
    "\n",
    "  # Turn on inference context manager\n",
    "  with torch.inference_mode():\n",
    "    # Loop through DataLoader batches\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "      # Send data to target device\n",
    "      X, y = X.to(device), y.to(device)\n",
    "\n",
    "      # 1. Forward pass\n",
    "      test_pred_logits = model(X)\n",
    "\n",
    "      # 2. Calculate the loss\n",
    "      loss = loss_fn(test_pred_logits, y)\n",
    "      test_loss += loss.item()\n",
    "\n",
    "      # 3. Calculate the accuracy\n",
    "      test_pred_labels = torch.argmax(torch.softmax(test_pred_logits, dim=1), dim=1)\n",
    "      test_acc += (test_pred_labels == y).sum().item() / len(test_pred_labels)\n",
    "\n",
    "    # Adjust metrics to get avarage loss and accuracy per batch\n",
    "    test_loss = test_loss / len(dataloader)\n",
    "    test_acc = test_acc / len(dataloader)\n",
    "\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a train() by combining train_step() and test_step()\n",
    "def train(\n",
    "    model: torch.nn.Module,\n",
    "    train_dataloader: torch.utils.data.DataLoader,\n",
    "    test_dataloader: torch.utils.data.DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    loss_fn: torch.nn.Module,\n",
    "    epochs: int):\n",
    "\n",
    "  # 1. Create empty results dictionary\n",
    "  results = {\n",
    "      \"train_loss\": [],\n",
    "      \"train_acc\": [],\n",
    "      \"test_loss\": [],\n",
    "      \"test_acc\": []\n",
    "  }\n",
    "\n",
    "  # 2. Loop through training and testing steps for a number of epochs\n",
    "  for epoch in tqdm(range(epochs)):\n",
    "    train_loss, train_acc = train_step(model=model,\n",
    "                                       dataloader=train_dataloader,\n",
    "                                       loss_fn=loss_fn,\n",
    "                                       optimizer=optimizer)\n",
    "    test_loss, test_acc = test_step(model=model,\n",
    "                                    dataloader=test_dataloader,\n",
    "                                    loss_fn=loss_fn)\n",
    "    # 4. Print out what's happening\n",
    "    print(f\"Epoch: {epoch+1} | \"\n",
    "    f\"train_loss: {train_loss:.4f} | \"\n",
    "    f\"train_acc: {train_acc:.4f} | \"\n",
    "    f\"test_loss: {test_loss:.4f} | \"\n",
    "    f\"test_acc: {test_acc:.4f}\")\n",
    "\n",
    "    # 5. Update results dictionary\n",
    "    # We have to make sure all data is moved to CPU and converted to float for storage\n",
    "    results[\"train_loss\"].append(train_loss.item() if isinstance(train_loss, torch.Tensor) else train_loss)\n",
    "    results[\"train_acc\"].append(train_acc.item() if isinstance(train_acc, torch.Tensor) else train_acc)\n",
    "    results[\"test_loss\"].append(test_loss.item() if isinstance(test_loss, torch.Tensor) else test_loss)\n",
    "    results[\"test_loss\"].append(test_loss.item() if isinstance(test_loss, torch.Tensor) else test_loss)\n",
    "\n",
    "  # 6. Return filled results at the end of the epoch\n",
    "  return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the timer\n",
    "start_time = timer()\n",
    "\n",
    "# Train model\n",
    "model_results = train(\n",
    "    model=model,\n",
    "    train_dataloader=train_loader,\n",
    "    test_dataloader=test_loader,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    epochs=NUM_EPOCHS\n",
    ")\n",
    "\n",
    "# End the timer and print out how long it took\n",
    "end_time = timer()\n",
    "print(f\"Total training time: {end_time-start_time:.3f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jupyter nbconvert --ClearMetadataPreprocessor.enabled=True --ClearOutputPreprocessor.enabled=True --to notebook --inplace /content/drive/MyDrive/Colab Notebooks/GoogleNet_FineTune_Pre_Trained_Model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
